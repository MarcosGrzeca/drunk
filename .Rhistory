hora,
erroParseado as numeroErros,
(SELECT GROUP_CONCAT(tn.palavra)
FROM tweets_nlp tn
WHERE tn.idTweetInterno = t.idInterno
GROUP BY tn.idTweetInterno) AS entidades
FROM tweets t
WHERE textparser <> ''
AND id <> 462478714693890048
AND q1 IS NOT NULL")
dados$resposta[is.na(dados$resposta)] <- 0
dados$resposta <- as.factor(dados$resposta)
dados$textParser <- enc2utf8(dados$textParser)
dados$numeroErros[dados$numeroErros > 1] <- 1
dados$textParser <- iconv(dados$textParser, to='ASCII//TRANSLIT')
dados$hashtags = gsub("#", "#tag_", dados$hashtags)
dados <- discretizarHora(dados)
clearConsole()
if (!require("text2vec")) {
install.packages("text2vec")
}
library(text2vec)
library(data.table)
library(SnowballC)
setDT(dados)
setkey(dados, id)
stem_tokenizer1 =function(x) {
tokens = word_tokenizer(x)
lapply(tokens, SnowballC::wordStem, language="en")
}
dados$textParser = sub("'", "", dados$textParser)
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(dados$textParser,
preprocessor = prep_fun,
#                  tokenizer = stem_tokenizer1,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
stop_words = tm::stopwords("en")
vocab = create_vocabulary(it_train, stopwords = stop_words, ngram = c(1L, 2L))
vectorizer = vocab_vectorizer(vocab)
dtm_train_texto = create_dtm(it_train, vectorizer)
it_train_hash = itoken(dados$hashtags,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocabHashTags = create_vocabulary(it_train_hash)
vectorizerHashTags = vocab_vectorizer(vocabHashTags)
dtm_train_hash_tags = create_dtm(it_train_hash, vectorizerHashTags)
it_train = itoken(strsplit(dados$entidades, ","),
ids = dados$id,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vectorizer = vocab_vectorizer(vocab)
dataFrameEntidades = create_dtm(it_train, vectorizer)
dataFrameEntidades <- as.data.frame(as.matrix(dataFrameEntidades))
#it_train = itoken(strsplit(dados$grams, ","),
#                  ids = dados$id,
#progressbar = TRUE)
#vocab = create_vocabulary(it_train)
#vectorizer = vocab_vectorizer(vocab)
#dataFrameGram = create_dtm(it_train, vectorizer)
#dataFrameGram <- as.data.frame(as.matrix(dataFrameGram))
#Concatenar resultados
dataFrameTexto <- as.data.frame(as.matrix(dtm_train_texto))
dataFrameHash <- as.data.frame(as.matrix(dtm_train_hash_tags))
clearConsole()
library(rowr)
library(RWeka)
maFinal <- cbind.fill(dados, dataFrameTexto)
maFinal <- cbind.fill(maFinal, dataFrameHash)
maFinal <- cbind.fill(maFinal, dataFrameEntidades)
maFinal <- subset(maFinal, select = -c(textParser, id, hashtags, textoCompleto, entidades))
save(maFinal, file = "2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
source(file_path_as_absolute("processadores/discretizar.R"))
#Configuracoes
DATABASE <- "icwsm"
clearConsole();
dados <- query("SELECT t.id,
q1 AS resposta,
textParser,
textoParserEmoticom AS textoCompleto,
hashtags,
emoticonPos,
emoticonNeg,
hora,
erroParseado as numeroErros,
(SELECT GROUP_CONCAT(tn.palavra)
FROM tweets_nlp tn
WHERE tn.idTweetInterno = t.idInterno
GROUP BY tn.idTweetInterno) AS entidades
FROM tweets t
WHERE textparser <> ''
AND id <> 462478714693890048
AND q1 IS NOT NULL")
dados$resposta[is.na(dados$resposta)] <- 0
dados$resposta <- as.factor(dados$resposta)
dados$textParser <- enc2utf8(dados$textParser)
dados$numeroErros[dados$numeroErros > 1] <- 1
dados$textParser <- iconv(dados$textParser, to='ASCII//TRANSLIT')
dados$hashtags = gsub("#", "#tag_", dados$hashtags)
dados <- discretizarHora(dados)
clearConsole()
if (!require("text2vec")) {
install.packages("text2vec")
}
library(text2vec)
library(data.table)
library(SnowballC)
setDT(dados)
setkey(dados, id)
stem_tokenizer1 =function(x) {
tokens = word_tokenizer(x)
lapply(tokens, SnowballC::wordStem, language="en")
}
dados$textParser = sub("'", "", dados$textParser)
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(dados$textParser,
preprocessor = prep_fun,
#                  tokenizer = stem_tokenizer1,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
stop_words = tm::stopwords("en")
vocab = create_vocabulary(it_train, stopwords = stop_words, ngram = c(1L, 2L))
vectorizer = vocab_vectorizer(vocab)
dtm_train_texto = create_dtm(it_train, vectorizer)
it_train_hash = itoken(dados$hashtags,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocabHashTags = create_vocabulary(it_train_hash)
vectorizerHashTags = vocab_vectorizer(vocabHashTags)
dtm_train_hash_tags = create_dtm(it_train_hash, vectorizerHashTags)
it_train = itoken(strsplit(dados$entidades, ","),
ids = dados$id,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vectorizer = vocab_vectorizer(vocab)
dataFrameEntidades = create_dtm(it_train, vectorizer)
dataFrameEntidades <- as.data.frame(as.matrix(dataFrameEntidades))
#it_train = itoken(strsplit(dados$grams, ","),
#                  ids = dados$id,
#progressbar = TRUE)
#vocab = create_vocabulary(it_train)
#vectorizer = vocab_vectorizer(vocab)
#dataFrameGram = create_dtm(it_train, vectorizer)
#dataFrameGram <- as.data.frame(as.matrix(dataFrameGram))
#Concatenar resultados
dataFrameTexto <- as.data.frame(as.matrix(dtm_train_texto))
dataFrameHash <- as.data.frame(as.matrix(dtm_train_hash_tags))
clearConsole()
library(rowr)
library(RWeka)
maFinal <- cbind.fill(dados, dataFrameTexto)
maFinal <- cbind.fill(maFinal, dataFrameHash)
maFinal <- cbind.fill(maFinal, dataFrameEntidades)
maFinal <- subset(maFinal, select = -c(textParser, id, hashtags, textoCompleto, entidades))
save(maFinal, file = "2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
nrow(maFinal)
predict(twoGramEntidadesHoraErroNotNull, subset(maFinal,    select = -c(resposta)))
load("mardigras/mardigras_compare.RData")
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
predict(twoGramEntidadesHoraErroNotNull, subset(maFinal,    select = -c(resposta)))
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
nrow(maFinal)
predict(twoGramEntidadesHoraErroNotNull, subset(maFinal, select = -c(resposta)))
load("mardigras/mardigras_compare.RData")
resultados <- data.frame(matrix(ncol = 4, nrow = 0))
names(resultados) <- c("Baseline", "F1", "Precisão", "Revocação")
load("mardigras/mardigras_compare.RData")
ls()
treegram25
predict(twoGramEntidadesHoraErroNotNull, subset(maFinal, select = -c(resposta)))
predict(treegram25, subset(maFinal, select = -c(resposta)))
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
predict(treegram25, subset(maFinal, select = -c(resposta)))
rm("treegram25")
save.image(file = "mardigras/mardigras_compare.RData")
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
parte1 <- subset(maFinal, select = -c(drunk, drink, bacardi, emoticonPos))
parte2 <- subset(maFinal, select = c(drunk, drink, bacardi, emoticonPos))
library(rowr)
library(RWeka)
maFinalTwo <- cbind.fill(parte1, parte2)
save(maFinalTwo, file="mardigras/2gram-entidades-hora-erro-not-null-new-test_two.Rda")
View(maFinalTwo)
colnames(maFinalTwo)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
maFinal$drunk
maFinal$jururubeba
maFinal$jururubeba
colnames(maFinal)
colunasPermitidas <- colnames(maFinal)
library(rowr)
library(RWeka)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
colunasPermitidas <- colnames(maFinal)
View(colunasPermitidas)
colunasPermitidas
load("mardigras/2gram-entidades-hora-erro-not-null-new-test_three.Rda")
load("mardigras/2gram-entidades-hora-erro-not-null-new-test_three.Rda")
dataFrameTexto <- maFinal[names(colunasPermitidas)]
colunasPermitidas
colnames(maFinal)
load("2110/rdas/2gram-entidades-hora-erro-not-null.Rda")
dataFrameTexto <- maFinal[names(colunasPermitidas)]
load("mardigras/2gram-entidades.Rda")
dataFrameTexto <- maFinal[names(colunasPermitidas)]
View(dataFrameTexto)
maFinal$drinking_like
maFinal$drink
maFinal$drink
colunasPermitidas$drink
colunasPermitidas
maFinal$lisa
maFinal$apply_job
maFinal$millar
maFinal$drink
dataFrameTexto$dink
dataFrameTexto <- maFinal[names(drink)]
summary(colunasPermitidas)
aspectosManter <- c(drink)
aspectosManter <- c(aspectosManter, drink)
aspectosManter <- c()
aspectosManter <- c(aspectosManter, drink)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
library(rowr)
library(RWeka)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
origem <- maFinal
cols <- colnames(origem)
aspectos <- sort(colSums(dataFrameTexto), decreasing = TRUE)
aspectosManter <- c()
for(i in 1:length(cols)) {
aspectosManter <- c(aspectosManter, cols[i])
}
maFinal$drink
load("mardigras/2gram-entidades.Rda")
dataFrameTexto <- maFinal[names(aspectosManter)]
dataFrameTexto$dink
dataFrameTexto$drink
View(dataFrameTexto)
aspectosManter
View(maFinal)
aspectosManter <- c(aspectosManter, "goodbye")
maFinal$goodbye
dataFrameTexto <- maFinal[names(aspectosManter)]
aspectosManter
dataFrameTexto$goodbye
View(dataFrameTexto)
library(rowr)
library(RWeka)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
origem <- maFinal
cols <- colnames(origem)
aspectosManter <- c()
for(i in 1:length(cols)) {
#aspectosManter <- c(aspectosManter, cols[i])
}
aspectosManter <- c(aspectosManter, "goodbye")
load("mardigras/2gram-entidades.Rda")
final <- maFinal
final$goodbye
dataFrameTexto <- final[names(aspectosManter)]
dataFrameTexto$goodbye
View(dataFrameTexto)
aspectosManter
dataFrameTexto <- final[goodbye]
dataFrameTexto <- final["goodbye"]
dataFrameTexto$goodbye
View(dataFrameTexto)
names(aspectosManter)
library(rowr)
library(RWeka)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
origem <- maFinal
cols <- colnames(origem)
aspectos <- sort(colSums(cols), decreasing = TRUE)
aspectosManter <- c()
for(i in 1:length(aspectos)) {
aspectosManter <- c(aspectosManter, aspectos[i])
}
names(aspectosManter)
cols <- colnames(origem)
aspectos <- sort(colSums(origem), decreasing = TRUE)
library(rowr)
library(RWeka)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
origem <- maFinal
cols <- colnames(origem)
aspectos <- sort(colSums(origem), decreasing = TRUE)
aspectosManter <- c()
for(i in 1:length(aspectos)) {
aspectosManter <- c(aspectosManter, aspectos[i])
}
names(aspectosManter)
cols <- colnames(origem)
aspectos <- sort(colSums(origem), decreasing = TRUE)
library(rowr)
library(RWeka)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
origem <- maFinal
cols <- colnames(origem)
aspectosManter <- c()
length(cols)
for(i in 1:length(cols)) {
aspectosManter <- c(aspectosManter, cols[i])
}
names(aspectosManter)
aspectosManter
load("mardigras/2gram-entidades.Rda")
final <- maFinal
final$goodbye
dataFrameTexto <- final[aspectosManter]
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
dataFrameTexto <- maFinal
cols <- colnames(dataFrameTexto)
aspectos <- sort(colSums(dataFrameTexto), decreasing = TRUE)
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
source(file_path_as_absolute("processadores/discretizar.R"))
DATABASE <- "icwsm"
clearConsole();
dados <- query("SELECT t.id, q1 AS resposta, textParser, textoParserEmoticom AS textoCompleto, hashtags, emoticonPos,	emoticonNeg FROM tweets t WHERE textparser <> '' AND id <> 462478714693890048 AND q1 IS NOT NULL")
dados$resposta[is.na(dados$resposta)] <- 0
dados$resposta <- as.factor(dados$resposta)
dados$textParser <- enc2utf8(dados$textParser)
dados$hashtags <- enc2utf8(dados$hashtags)
clearConsole()
if (!require("text2vec")) {
install.packages("text2vec")
}
library(text2vec)
library(data.table)
library(SnowballC)
setDT(dados)
setkey(dados, id)
stem_tokenizer1 =function(x) {
tokens = word_tokenizer(x)
lapply(tokens, SnowballC::wordStem, language="en")
}
dados$textParser = sub("'", "", dados$textParser)
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(dados$textParser,
preprocessor = prep_fun,
#                  tokenizer = stem_tokenizer1,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
stop_words = tm::stopwords("en")
vocab = create_vocabulary(it_train, stopwords = stop_words, ngram = c(1L, 3L))
vectorizer = vocab_vectorizer(vocab)
dtm_train_texto = create_dtm(it_train, vectorizer)
it_train_hash = itoken(dados$hashtags,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocabHashTags = create_vocabulary(it_train_hash)
vectorizerHashTags = vocab_vectorizer(vocabHashTags)
dtm_train_hash_tags = create_dtm(it_train_hash, vectorizerHashTags)
dataFrameTexto <- as.data.frame(as.matrix(dtm_train_texto))
dataFrameHash <- as.data.frame(as.matrix(dtm_train_hash_tags))
clearConsole()
library(rowr)
library(RWeka)
clearConsole()
library(rowr)
library(RWeka)
cols <- colnames(dataFrameTexto)
aspectos <- sort(colSums(dataFrameTexto), decreasing = TRUE)
manter <- round(length(aspectos) * 0.25)
aspectosManter <- c()
aspectosRemover <- c()
for(i in 1:length(aspectos)) {
if (i <= manter) {
aspectosManter <- c(aspectosManter, aspectos[i])
} else {
aspectosRemover <- c(aspectosRemover, aspectos[i])
}
}
names(aspectosManter)
names(aspectosManter)
aspectosManter <- c()
for(i in 1:length(aspectos)) {
if (i <= manter) {
aspectosManter <- c(aspectosManter, cols[i])
} else {
aspectosRemover <- c(aspectosRemover, aspectos[i])
}
}
names(aspectosManter)
aspectosManter
aspectos[10]
cols[10]
for(i in 1:length(aspectos)) {
if (i <= manter) {
aspectosManter <- c(aspectosManter, aspectos[i])
} else {
aspectosRemover <- c(aspectosRemover, aspectos[i])
}
}
names(aspectosManter)
marcos <- names(aspectosManter)
class(marcos)
aspectosManter
A <- c("marcos")
all(A %in% names(aspectosManter))
A <- c("beer")
all(A %in% names(aspectosManter))
A <- c("beer_teste")
all(A %in% names(aspectosManter))
A <- c("drink")
all(A %in% names(aspectosManter))
library(rowr)
library(RWeka)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
origem <- maFinal
load("mardigras/2gram-entidades.Rda")
final <- maFinal
colsOrigem <- colnames(origem)
aspectosManter <- c()
for(i in 1:length(cols)) {
aspectosManter <- c(aspectosManter, cols[i])
}
colsOrigem <- colnames(origem)
aspectosManter <- c()
for(i in 1:length(colsOrigem)) {
aspectosManter <- c(aspectosManter, colsOrigem[i])
}
aspectosManter
library(rowr)
library(RWeka)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
origem <- maFinal
load("mardigras/2gram-entidades.Rda")
destino <- maFinal
colsOrigem <- colnames(origem)
colsDestino <- colname(destino)
aspectosManter <- c()
for(i in 1:length(colsOrigem)) {
aspectosManter <- c(aspectosManter, colsOrigem[i])
if (!all(colsOrigem[i] %in% colsDestino)) {
print(colsOrigem[i])
}
}
colsDestino <- colnames(destino)
colsDestino <- colnames(destino)
aspectosManter <- c()
for(i in 1:length(colsOrigem)) {
aspectosManter <- c(aspectosManter, colsOrigem[i])
if (!all(colsOrigem[i] %in% colsDestino)) {
print(colsOrigem[i])
}
}
colsOrigem <- c("marcos", "drink", "beer")
colsDestino <- c("drink", "beer")
aspectosManter <- c()
for(i in 1:length(colsOrigem)) {
aspectosManter <- c(aspectosManter, colsOrigem[i])
if (!all(colsOrigem[i] %in% colsDestino)) {
print(colsOrigem[i])
#destino$colsOrigem[i] = 0
}
}
for(i in 1:length(colsOrigem)) {
aspectosManter <- c(aspectosManter, colsOrigem[i])
if (!all(colsOrigem[i] %in% colsDestino)) {
print(colsOrigem[i])
destino$colsOrigem[i] = 0
}
}
library(rowr)
library(RWeka)
load("2110/rdas/2gram-entidades-hora-erro-not-null-new-test.Rda")
origem <- maFinal
load("mardigras/2gram-entidades.Rda")
destino <- maFinal
colsOrigem <- colnames(origem)
colsDestino <- colnames(destino)
aspectosManter <- c()
for(i in 1:length(colsOrigem)) {
aspectosManter <- c(aspectosManter, colsOrigem[i])
if (!all(colsOrigem[i] %in% colsDestino)) {
destino$colsOrigem[i] = 0
}
}
for(i in 1:length(colsOrigem)) {
aspectosManter <- c(aspectosManter, colsOrigem[i])
col <- colsOrigem[i]
if (!all(colsOrigem[i] %in% colsDestino)) {
destino$col = 0
}
}
for(i in 1:length(colsOrigem)) {
aspectosManter <- c(aspectosManter, colsOrigem[i])
col <- colsOrigem[i]
if (!all(colsOrigem[i] %in% colsDestino)) {
destino[[col]] = 0
}
}
