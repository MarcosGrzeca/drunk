unnest_tokens(word, text)
text_df %>%
unnest_tokens(word, text)
text_df %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
nrcjoy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
text_df %>%
inner_join(nrcjoy) %>%
count(word, sort = TRUE)
text_df %>%
inner_join(nrcjoy)
m <- text_df %>%
unnest_tokens(word, text)
m %>%
inner_join(nrcjoy)
m %>%
inner_join(nrcjoy) %>%
count(word, sort = TRUE)
m %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE)
m
m %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE)
m %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment))
m %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment))
m
m %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment))
m %>%
right_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE)
library(tidyverse)
library(tidytext)
library(stringr)
library(glue)
files <- list.files("presidentes")
files
files <- list.files("../presidentes")
files
list.files("../")
list.files("sentimento/presidentes")
files <- list.files("sentimento/presidentes")
files
GetSentiment <- function(file){
# get the file
fileName <- glue("../input/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) %>% # # of positive words - # of negative owrds
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
GetSentiment(files[1])
GetSentiment <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) %>% # # of positive words - # of negative owrds
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
GetSentiment(files[1])
sentiments <- data_frame()
for(i in files){
sentiments <- rbind(sentiments, GetSentiment(i))
}
sentiments
sentiments
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
# get a list of the files in the input directory
files <- list.files("sentimento/presidentes")
files
GetSentiment <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) %>% # # of positive words - # of negative owrds
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
GetSentimentNrc <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
# test: should return
# negative  positive    sentiment   file    year    president
# 117   240 123 Bush_1989.txt   1989    Bush
sentiments <- data_frame()
# get the sentiments for each file in our datset
for(i in files){
sentiments <- rbind(sentiments, GetSentiment(i))
}
sentiments
sentimentsNrc <- data_frame()
# get the sentiments for each file in our datset
for(i in files){
sentimentsNrc <- rbind(sentiments, GetSentimentNrc(i))
}
sentimentsNrc
GetSentimentNrc(files[1])
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
# get a list of the files in the input directory
files <- list.files("sentimento/presidentes")
files
GetSentiment <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) %>% # # of positive words - # of negative owrds
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
GetSentimentNrc <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
# test: should return
# negative  positive    sentiment   file    year    president
# 117   240 123 Bush_1989.txt   1989    Bush
sentiments <- data_frame()
# get the sentiments for each file in our datset
for(i in files){
sentiments <- rbind(sentiments, GetSentiment(i))
}
sentiments
sentimentsNrc <- data_frame()
# get the sentiments for each file in our datset
for(i in files){
sentimentsNrc <- rbind(sentimentsNrc, GetSentimentNrc(i))
}
sentimentsNrc
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
# get a list of the files in the input directory
files <- list.files("sentimento/presidentes")
files
GetSentiment <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) %>% # # of positive words - # of negative owrds
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
GetSentimentNrc <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
# test: should return
# negative  positive    sentiment   file    year    president
# 117   240 123 Bush_1989.txt   1989    Bush
sentiments <- data_frame()
# get the sentiments for each file in our datset
for(i in files){
sentiments <- rbind(sentiments, GetSentiment(i))
}
sentiments
sentimentsNrc <- data_frame()
# get the sentiments for each file in our datset
for(i in files){
sentimentsNrc <- rbind(sentimentsNrc, GetSentimentNrc(i))
}
sentimentsNrc
files
sentimentsNrc <- data_frame()
for(i in files){
sentimentsNrc <- rbind(sentimentsNrc, GetSentimentNrc(i))
}
GetSentimentNrc(files[5])
GetSentimentNrc(files[5])
GetSentimentNrc(files[5])
get_sentiments("nrc")
GetSentimentNrc(files[5])
mutate(sentiment = get_sentiment("I'm feeling so good!"))
library(sentimentr)
mutate(sentiment = get_sentiment("I'm feeling so good!"))
install.packages("devtools")
devtools::install_github("exploratory-io/exploratory_func")
library(exploratory)
devtools::install_github("exploratory-io/exploratory_func")
devtools::install_github("exploratory-io/exploratory_func")
library(exploratory)
library(sentimentr)
mutate(sentiment = get_sentiment("I'm feeling so good!"))
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
mutate(sentiment = get_sentiment("I'm feeling so good!"))
mutate(sentiment = get_sentiment("Im feeling so good!"))
text <- "Iâ€™m not feeling good."
mutate(sentiment = get_sentiment(text))
mytext <- c(
'do you like it?  But I hate really bad dogs',
'I am the best friend.',
'Do you really like it?  I\'m not a fan'
)
mytext <- get_sentences(mytext)
sentiment(mytext)
GetSentimentNrc(files[5])
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
files <- list.files("sentimento/presidentes")
files
GetSentiment <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) %>% # # of positive words - # of negative owrds
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
GetSentimentNrc <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
sentiments <- data_frame()
for(i in files){
sentiments <- rbind(sentiments, GetSentiment(i))
}
sentiments
sentimentsNrc <- data_frame()
for(i in files){
sentimentsNrc <- rbind(sentimentsNrc, GetSentimentNrc(i))
}
GetSentimentNrc(files[5])
tes <- get_sentiments("nrc")
tes$anger
View(tes)
tes
tes <- GetSentimentNrc(files[5])
tes
tes$anger
tes <- GetSentimentNrc(files[5])
tes$anger
tes$fear
tes$sadness
for(i in files){
sentimentsNrc <- rbind(sentimentsNrc, GetSentimentNrc(i))
}
library(tidyverse)
library(tidytext)
library(glue)
library(stringr)
files <- list.files("sentimento/presidentes")
GetSentiment <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("bing")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(sentiment = positive - negative) %>% # # of positive words - # of negative owrds
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
GetSentimentNrc <- function(file){
# get the file
fileName <- glue("sentimento/presidentes/", file, sep = "")
# get rid of any sneaky trailing spaces
fileName <- trimws(fileName)
# read in the new file
fileText <- glue(read_file(fileName))
# remove any dollar signs (they're special characters in R)
fileText <- gsub("\\$", "", fileText)
# tokenize
tokens <- data_frame(text = fileText) %>% unnest_tokens(word, text)
# get the sentiment from the first text:
sentiment <- tokens %>%
inner_join(get_sentiments("nrc")) %>% # pull out only sentimen words
count(sentiment) %>% # count the # of positive & negative words
spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
mutate(file = file) %>% # add the name of our file
mutate(year = as.numeric(str_match(file, "\\d{4}"))) %>% # add the year
mutate(president = str_match(file, "(.*?)_")[2]) # add president
# return our sentiment dataframe
return(sentiment)
}
for(i in files){
sentiments <- rbind(sentiments, GetSentiment(i))
}
sentiments
sentimentsNrc <- data_frame()
sentimentsNrc
tes <- GetSentimentNrc(files[5])
tes$anger
tes$sadness
tes$fear
for(i in files){
sentimentsNrc <- rbind(sentimentsNrc, GetSentimentNrc(i))
}
files
sentiments <- data_frame()
sentimentsNrc
tes$joy
tes <- GetSentimentNrc(files[4])
tes$anger
tes$anticipation
tes$disgust
tes$fear
tes$joy
tes$negative
tes$positive
tes$sadness
tes$surprise
tes$trust
