layout(title = "Comparativo entre Trabalhos Relacionados", xaxis = list(showline = TRUE, showgrid = TRUE, showarrow = FALSE, title = "", tickangle = 20),
yaxis = list(title = ""),
margin = list(b = 100),
barmode = 'group')
options(max.print = 99999999)
source(file_path_as_absolute("functions.R"))
library(tools)
source(file_path_as_absolute("processadores/discretizar.R"))
DATABASE <- "icwsm"
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
source(file_path_as_absolute("processadores/discretizar.R"))
DATABASE <- "icwsm"
clearConsole();
dadosQ1 <- query("SELECT t.id, q1 as resposta, textParser, textoParserEmoticom as textoCompleto, hashtags, emoticonPos, emoticonNeg, sentiment, sentimentH, localCount, organizationCount, moneyCount, personCount, numeroErros, numeroConjuncoes, taxaSubstantivo, taxaAdjetivo, taxaAdverbio, taxaVerbo, palavroes, hora, tl.name as nomeEstabelecimento, tl.category as categoriaEstabelecimento, diaSemana FROM tweets t LEFT JOIN tweet_localizacao tl ON tl.idTweetInterno = t.idInterno AND distance = 100")
dados <- dadosQ1
dados$resposta[is.na(dados$resposta)] <- 0
dados$numeroErros[dados$numeroErros > 1] <- 1
dados$resposta <- as.factor(dados$resposta)
dados$palavroes[dados$palavroes > 1] <- 1
clearConsole()
dados <- discretizarTaxas(dados)
dados <- discretizarHora(dados)
dados <- discretizarSentimentos(dados);
if (!require("text2vec")) {
install.packages("text2vec")
}
library(text2vec)
library(data.table)
library(SnowballC)
setDT(dados)
setkey(dados, id)
stem_tokenizer1 =function(x) {
tokens = word_tokenizer(x)
lapply(tokens, SnowballC::wordStem, language="en")
}
dados$textParser = sub("'", "", dados$textParser)
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(dados$textParser,
preprocessor = prep_fun,
#                  tokenizer = stem_tokenizer1,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
stop_words = tm::stopwords("en")
vocab = create_vocabulary(it_train, stopwords = stop_words, ngram = c(1L, 2L))
vectorizer = vocab_vectorizer(vocab)
dtm_train_texto = create_dtm(it_train, vectorizer)
it_train_hash = itoken(dados$hashtags,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocabHashTags = create_vocabulary(it_train_hash)
vectorizerHashTags = vocab_vectorizer(vocabHashTags)
dtm_train_hash_tags = create_dtm(it_train_hash, vectorizerHashTags)
dataFrameTexto <- as.data.frame(as.matrix(dtm_train_texto))
dataFrameHash <- as.data.frame(as.matrix(dtm_train_hash_tags))
clearConsole()
dados$categoriaEstabelecimento = sub(" ", "_", dados$categoriaEstabelecimento)
it_train = itoken(dados$categoriaEstabelecimento,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocabEstabelecimento = create_vocabulary(it_train, stopwords = stop_words)
vocabEstabelecimento = prune_vocabulary(vocabEstabelecimento,
term_count_min = 5,
doc_proportion_max = 0.9,
doc_proportion_min = 0.001)
vectorizerEstabelecimento = vocab_vectorizer(vocabEstabelecimento)
dataFrameEstabelecimento = create_dtm(it_train, vectorizerEstabelecimento)
dataFrameEstabelecimento <- as.data.frame(as.matrix(dataFrameEstabelecimento))
it_train = itoken(strsplit(dados$entidades, ","),
ids = dados$id,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vectorizer = vocab_vectorizer(vocab)
dataFrameEntidades = create_dtm(it_train, vectorizer)
dataFrameEntidades <- as.data.frame(as.matrix(dataFrameEntidades))
it_train = itoken(strsplit(dados$grams, ","),
ids = dados$id,
progressbar = TRUE)
maFinal <- cbind.fill(dados, dataFrameTexto)
library(rowr)
library(RWeka)
maFinal <- cbind.fill(dados, dataFrameTexto)
maFinal <- cbind.fill(maFinal, dataFrameHash)
maFinal <- cbind.fill(maFinal, dataFrameEstabelecimento)
maFinal <- cbind.fill(maFinal, dataFrameEntidades)
maFinal <- cbind.fill(dados, dataFrameTexto)
maFinal <- cbind.fill(maFinal, dataFrameHash)
maFinal <- cbind.fill(maFinal, dataFrameEstabelecimento)
maFinal <- subset(maFinal, select = -c(textParser, id, hashtags, textoCompleto, categoriaEstabelecimento, nomeEstabelecimento, entidades, grams))
maFinal <- subset(maFinal, select = -c(textParser, id, hashtags, textoCompleto, categoriaEstabelecimento, nomeEstabelecimento))
save(maFinal, file = "dados_2110_2gram_estabelecimento.Rda")
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
source(file_path_as_absolute("processadores/discretizar.R"))
DATABASE <- "icwsm"
clearConsole();
dadosQ1 <- query("SELECT t.id,
q1                  AS resposta,
textparser,
textoparseremoticom AS textoCompleto,
hashtags,
emoticonpos,
emoticonneg
FROM   tweets t ")
dados <- dadosQ1
View(dados)
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
source(file_path_as_absolute("processadores/discretizar.R"))
DATABASE <- "icwsm"
clearConsole();
dadosQ1 <- query("SELECT t.id,
q1                  AS resposta,
textparser,
textoparseremoticom AS textoCompleto,
hashtags,
emoticonpos,
emoticonneg
FROM   tweets t ")
dados <- dadosQ1
dados$resposta[is.na(dados$resposta)] <- 0
clearConsole()
if (!require("text2vec")) {
install.packages("text2vec")
}
library(text2vec)
library(data.table)
library(SnowballC)
setDT(dados)
load("2110/rdas/compare21.RData")
View(resultados)
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
source(file_path_as_absolute("processadores/discretizar.R"))
DATABASE <- "icwsm"
clearConsole();
dados <- query("SELECT t.id,
t.idInterno,
q1 AS resposta,
textParser,
textoParserEmoticom AS textoCompleto,
hashtags,
emoticonPos,
emoticonNeg,
(
SELECT GROUP_CONCAT(DISTINCT(REPLACE(resource, "http://dbpedia.org/resource/", "")))
FROM
(
SELECT c.resource as resource, tn.idTweetInterno
FROM tweets_nlp tn
JOIN conceito c ON c.palavra = tn.palavra
WHERE c.sucesso = 1
UNION ALL
SELECT c.resource as resource, tn.idTweetInterno
FROM tweets_gram tn
JOIN conceito c ON c.palavra = tn.palavra
WHERE c.sucesso = 1
GROUP BY 1,2
) as louco
WHERE louco.idTweetInterno = t.idInterno
)
FROM tweets t
LIMIT 10
")
dados <- query("SELECT t.id,
t.idInterno,
q1 AS resposta,
textParser,
textoParserEmoticom AS textoCompleto,
hashtags,
emoticonPos,
emoticonNeg,
(
SELECT GROUP_CONCAT(DISTINCT(REPLACE(resource, 'http://dbpedia.org/resource/', '')))
FROM
(
SELECT c.resource as resource, tn.idTweetInterno
FROM tweets_nlp tn
JOIN conceito c ON c.palavra = tn.palavra
WHERE c.sucesso = 1
UNION ALL
SELECT c.resource as resource, tn.idTweetInterno
FROM tweets_gram tn
JOIN conceito c ON c.palavra = tn.palavra
WHERE c.sucesso = 1
GROUP BY 1,2
) as louco
WHERE louco.idTweetInterno = t.idInterno
)
FROM tweets t
LIMIT 10
")
dados <- query("SELECT t.id,
t.idInterno,
q1 AS resposta,
textParser,
textoParserEmoticom AS textoCompleto,
hashtags,
emoticonPos,
emoticonNeg,
(
SELECT GROUP_CONCAT(DISTINCT(REPLACE(resource, 'http://dbpedia.org/resource/', '')))
FROM
(
SELECT c.resource as resource, tn.idTweetInterno
FROM tweets_nlp tn
JOIN conceito c ON c.palavra = tn.palavra
WHERE c.sucesso = 1
UNION ALL
SELECT c.resource as resource, tn.idTweetInterno
FROM tweets_gram tn
JOIN conceito c ON c.palavra = tn.palavra
WHERE c.sucesso = 1
GROUP BY 1,2
) as louco
WHERE louco.idTweetInterno = t.idInterno
)
FROM tweets t")
dados <- query("SELECT t.id,
t.idInterno,
q1 AS resposta,
textParser,
textoParserEmoticom AS textoCompleto,
hashtags,
emoticonPos,
emoticonNeg,
(
SELECT GROUP_CONCAT(DISTINCT(REPLACE(resource, 'http://dbpedia.org/resource/', '')))
FROM
(
SELECT c.resource as resource, tn.idTweetInterno
FROM tweets_nlp tn
JOIN conceito c ON c.palavra = tn.palavra
WHERE c.sucesso = 1
UNION ALL
SELECT c.resource as resource, tn.idTweetInterno
FROM tweets_gram tn
JOIN conceito c ON c.palavra = tn.palavra
WHERE c.sucesso = 1
GROUP BY 1,2
) as louco
WHERE louco.idTweetInterno = t.idInterno
) FROM tweets t")
dados$resposta[is.na(dados$resposta)] <- 0
dados$resposta <- as.factor(dados$resposta)
dados$textParser <- enc2utf8(dados$textParser)
clearConsole()
if (!require("text2vec")) {
install.packages("text2vec")
}
library(text2vec)
library(data.table)
library(SnowballC)
setDT(dados)
setkey(dados, id)
stem_tokenizer1 =function(x) {
tokens = word_tokenizer(x)
lapply(tokens, SnowballC::wordStem, language="en")
}
dados$textParser = sub("'", "", dados$textParser)
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(dados$textParser,
preprocessor = prep_fun,
#                  tokenizer = stem_tokenizer1,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
source(file_path_as_absolute("processadores/discretizar.R"))
DATABASE <- "icwsm"
clearConsole();
dados <- query("SELECT t.id,
q1 AS resposta,
textParser,
textoParserEmoticom AS textoCompleto,
hashtags,
emoticonPos,
emoticonNeg
(SELECT GROUP_CONCAT(ty.type)
FROM tweets_nlp tn
JOIN conceito c ON c.palavra = tn.palavra
JOIN resource_type ty ON ty.resource = c.resource
WHERE tn.idTweetInterno = t.idInterno
AND ty.`type` IN ('http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#SocialPerson',
'http://schema.org/Organization',
'http://dbpedia.org/ontology/Group',
'http://schema.org/MusicGroup',
'http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#NaturalPerson',
'http://schema.org/Product',
'http://dbpedia.org/class/yago/Rocket104099429',
'http://dbpedia.org/class/yago/Holder110180178',
'http://dbpedia.org/ontology/Artist',
'http://dbpedia.org/class/yago/Female109619168',
'http://dbpedia.org/class/yago/Child109918248',
'http://dbpedia.org/class/yago/Male109624168',
'http://dbpedia.org/class/yago/Document103217458',
'http://dbpedia.org/class/yago/AthleticFacility102752311',
'http://dbpedia.org/class/yago/Pool103982060',
'http://dbpedia.org/class/yago/PlasticArt103958097',
'http://dbpedia.org/class/yago/SolidFigure113863473',
'http://dbpedia.org/class/yago/Attacker109821253',
'http://dbpedia.org/class/yago/AcousticDevice102676261',
'http://dbpedia.org/class/yago/SignalingDevice104217718',
'http://dbpedia.org/class/yago/Anomaly114505821',
'http://dbpedia.org/class/yago/Defect114464005',
'http://dbpedia.org/class/yago/Climber113102409',
'http://dbpedia.org/class/yago/ComputerUser109951274',
'http://dbpedia.org/class/yago/Engineer109615807',
'http://dbpedia.org/class/yago/RootVegetable107710283',
'http://dbpedia.org/class/yago/SolanaceousVegetable107710007',
'http://dbpedia.org/class/yago/Stimulant104320126',
'http://dbpedia.org/class/yago/Ceramic102997391',
'http://dbpedia.org/class/yago/Biome107941945')
GROUP BY t.id) AS entidades,
(SELECT GROUP_CONCAT(ty.type)
FROM tweets_gram tn
JOIN conceito c ON c.palavra = tn.palavra
JOIN resource_type ty ON ty.resource = c.resource
WHERE tn.idTweetInterno = t.idInterno
AND ty.`type` IN ('http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#SocialPerson',
'http://schema.org/Organization',
'http://dbpedia.org/ontology/Group',
'http://schema.org/MusicGroup',
'http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#NaturalPerson',
'http://schema.org/Product',
'http://dbpedia.org/class/yago/Rocket104099429',
'http://dbpedia.org/class/yago/Holder110180178',
'http://dbpedia.org/ontology/Artist',
'http://dbpedia.org/class/yago/Female109619168',
'http://dbpedia.org/class/yago/Child109918248',
'http://dbpedia.org/class/yago/Male109624168',
'http://dbpedia.org/class/yago/Document103217458',
'http://dbpedia.org/class/yago/AthleticFacility102752311',
'http://dbpedia.org/class/yago/Pool103982060',
'http://dbpedia.org/class/yago/PlasticArt103958097',
'http://dbpedia.org/class/yago/SolidFigure113863473',
'http://dbpedia.org/class/yago/Attacker109821253',
'http://dbpedia.org/class/yago/AcousticDevice102676261',
'http://dbpedia.org/class/yago/SignalingDevice104217718',
'http://dbpedia.org/class/yago/Anomaly114505821',
'http://dbpedia.org/class/yago/Defect114464005',
'http://dbpedia.org/class/yago/Climber113102409',
'http://dbpedia.org/class/yago/ComputerUser109951274',
'http://dbpedia.org/class/yago/Engineer109615807',
'http://dbpedia.org/class/yago/RootVegetable107710283',
'http://dbpedia.org/class/yago/SolanaceousVegetable107710007',
'http://dbpedia.org/class/yago/Stimulant104320126',
'http://dbpedia.org/class/yago/Ceramic102997391',
'http://dbpedia.org/class/yago/Biome107941945')
GROUP BY t.id) AS resources
FROM tweets t")
dados <- query("SELECT t.id,
q1 AS resposta,
textParser,
textoParserEmoticom AS textoCompleto,
hashtags,
emoticonPos,
emoticonNeg,
(SELECT GROUP_CONCAT(ty.type)
FROM tweets_nlp tn
JOIN conceito c ON c.palavra = tn.palavra
JOIN resource_type ty ON ty.resource = c.resource
WHERE tn.idTweetInterno = t.idInterno
AND ty.`type` IN ('http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#SocialPerson',
'http://schema.org/Organization',
'http://dbpedia.org/ontology/Group',
'http://schema.org/MusicGroup',
'http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#NaturalPerson',
'http://schema.org/Product',
'http://dbpedia.org/class/yago/Rocket104099429',
'http://dbpedia.org/class/yago/Holder110180178',
'http://dbpedia.org/ontology/Artist',
'http://dbpedia.org/class/yago/Female109619168',
'http://dbpedia.org/class/yago/Child109918248',
'http://dbpedia.org/class/yago/Male109624168',
'http://dbpedia.org/class/yago/Document103217458',
'http://dbpedia.org/class/yago/AthleticFacility102752311',
'http://dbpedia.org/class/yago/Pool103982060',
'http://dbpedia.org/class/yago/PlasticArt103958097',
'http://dbpedia.org/class/yago/SolidFigure113863473',
'http://dbpedia.org/class/yago/Attacker109821253',
'http://dbpedia.org/class/yago/AcousticDevice102676261',
'http://dbpedia.org/class/yago/SignalingDevice104217718',
'http://dbpedia.org/class/yago/Anomaly114505821',
'http://dbpedia.org/class/yago/Defect114464005',
'http://dbpedia.org/class/yago/Climber113102409',
'http://dbpedia.org/class/yago/ComputerUser109951274',
'http://dbpedia.org/class/yago/Engineer109615807',
'http://dbpedia.org/class/yago/RootVegetable107710283',
'http://dbpedia.org/class/yago/SolanaceousVegetable107710007',
'http://dbpedia.org/class/yago/Stimulant104320126',
'http://dbpedia.org/class/yago/Ceramic102997391',
'http://dbpedia.org/class/yago/Biome107941945')
GROUP BY t.id) AS entidades,
(SELECT GROUP_CONCAT(ty.type)
FROM tweets_gram tn
JOIN conceito c ON c.palavra = tn.palavra
JOIN resource_type ty ON ty.resource = c.resource
WHERE tn.idTweetInterno = t.idInterno
AND ty.`type` IN ('http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#SocialPerson',
'http://schema.org/Organization',
'http://dbpedia.org/ontology/Group',
'http://schema.org/MusicGroup',
'http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#NaturalPerson',
'http://schema.org/Product',
'http://dbpedia.org/class/yago/Rocket104099429',
'http://dbpedia.org/class/yago/Holder110180178',
'http://dbpedia.org/ontology/Artist',
'http://dbpedia.org/class/yago/Female109619168',
'http://dbpedia.org/class/yago/Child109918248',
'http://dbpedia.org/class/yago/Male109624168',
'http://dbpedia.org/class/yago/Document103217458',
'http://dbpedia.org/class/yago/AthleticFacility102752311',
'http://dbpedia.org/class/yago/Pool103982060',
'http://dbpedia.org/class/yago/PlasticArt103958097',
'http://dbpedia.org/class/yago/SolidFigure113863473',
'http://dbpedia.org/class/yago/Attacker109821253',
'http://dbpedia.org/class/yago/AcousticDevice102676261',
'http://dbpedia.org/class/yago/SignalingDevice104217718',
'http://dbpedia.org/class/yago/Anomaly114505821',
'http://dbpedia.org/class/yago/Defect114464005',
'http://dbpedia.org/class/yago/Climber113102409',
'http://dbpedia.org/class/yago/ComputerUser109951274',
'http://dbpedia.org/class/yago/Engineer109615807',
'http://dbpedia.org/class/yago/RootVegetable107710283',
'http://dbpedia.org/class/yago/SolanaceousVegetable107710007',
'http://dbpedia.org/class/yago/Stimulant104320126',
'http://dbpedia.org/class/yago/Ceramic102997391',
'http://dbpedia.org/class/yago/Biome107941945')
GROUP BY t.id) AS resources
FROM tweets t")
load("2110/rdas/compare22.RData")
View(resultados)
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
source(file_path_as_absolute("processadores/discretizar.R"))
DATABASE <- "icwsm"
clearConsole();
dados <- query("SELECT t.id, q1 AS resposta, textParser, textoParserEmoticom AS textoCompleto, hashtags, emoticonPos,	emoticonNeg FROM tweets t WHERE textparser <> '' AND id <> 462478714693890048")
dados$resposta[is.na(dados$resposta)] <- 0
dados$resposta <- as.factor(dados$resposta)
dados$textParser <- enc2utf8(dados$textParser)
clearConsole()
if (!require("text2vec")) {
install.packages("text2vec")
}
library(text2vec)
library(data.table)
library(SnowballC)
setDT(dados)
setkey(dados, id)
stem_tokenizer1 =function(x) {
tokens = word_tokenizer(x)
lapply(tokens, SnowballC::wordStem, language="en")
}
dados$textParser = sub("'", "", dados$textParser)
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(dados$textParser,
preprocessor = prep_fun,
#                  tokenizer = stem_tokenizer1,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
stop_words = tm::stopwords("en")
vocab = create_vocabulary(it_train, stopwords = stop_words, ngram = c(1L, 3L))
vectorizer = vocab_vectorizer(vocab)
dtm_train_texto = create_dtm(it_train, vectorizer)
it_train_hash = itoken(dados$hashtags,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocabHashTags = create_vocabulary(it_train_hash)
vectorizerHashTags = vocab_vectorizer(vocabHashTags)
dtm_train_hash_tags = create_dtm(it_train_hash, vectorizerHashTags)
dataFrameTexto <- as.data.frame(as.matrix(dtm_train_texto))
dataFrameHash <- as.data.frame(as.matrix(dtm_train_hash_tags))
clearConsole()
library(rowr)
library(RWeka)
cols <- colnames(dataFrameTexto)
aspectos <- sort(colSums(dataFrameTexto), decreasing = TRUE)
manter <- round(length(aspectos) * 0.25)
aspectosManter <- c()
aspectosRemover <- c()
for(i in 1:length(aspectos)) {
if (i <= manter) {
aspectosManter <- c(aspectosManter, aspectos[i])
} else {
aspectosRemover <- c(aspectosRemover, aspectos[i])
}
}
dataFrameTexto <- dataFrameTexto[names(aspectosManter)]
maFinal <- cbind.fill(dados, dataFrameTexto)
maFinal <- cbind.fill(maFinal, dataFrameHash)
maFinal <- subset(maFinal, select = -c(textParser, id, hashtags, textoCompleto))
save(maFinal, file = "2110/rdas/3gram-25.Rda")
